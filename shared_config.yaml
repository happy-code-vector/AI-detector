# Shared configuration for AI Detector project
# This is the single source of truth for model and data parameters
# Both training and API read from this file

model:
  # Base model name from HuggingFace
  name: "microsoft/deberta-v3-large"

  # Where trained models are saved/loaded from
  checkpoint_dir: "api/models/checkpoint-best"

  # Device: auto, cuda, cpu
  device: "auto"

data:
  # Full dataset path (relative to project root)
  full_data_path: "training/data/custom/all_datasets_combined.json"

  # Test dataset path (subset for local testing on RTX 3060)
  test_data_path: "training/data/custom/test_subset.json"

  # Text processing limits
  max_sentences: 120
  max_words_per_sentence: 350

  # Data split ratios
  train_split: 0.8
  eval_split: 0.1
  test_split: 0.1

  # Test mode: use small subset for quick testing
  test_subset_size: 5000  # Number of samples for test training

training:
  # Training mode: "test" or "full"
  # test: uses small subset (test_subset_size samples) for quick local testing
  # full: uses entire dataset for production training on H100
  mode: "full"

  # batch_size: effective batch size = batch_size * gradient_accumulation_steps
  # RTX 3060 (12GB): batch_size=2, gradient_accumulation=8
  # RTX 3090 (24GB): batch_size=8, gradient_accumulation=4
  # H100 (80GB): batch_size=16, gradient_accumulation=2
  batch_size: 4
  gradient_accumulation_steps: 4

  # Learning rate
  learning_rate: 2e-5

  # Epochs
  epochs: 3

  # Max sequence length
  max_length: 512

  # Gradient clipping
  max_grad_norm: 1.0

  # Warmup: use ratio (scales with dataset size)
  # 0.05 = 5% of training steps for warmup
  warmup_ratio: 0.05

  # Weight decay for regularization (prevents overfitting)
  weight_decay: 0.01

  # Logging/evaluation steps
  logging_steps: 50
  eval_steps: 500
  save_steps: 500

  # LoRA settings for efficient fine-tuning
  use_peft: true
  lora_r: 16
  lora_alpha: 32
  lora_dropout: 0.1

api:
  # API server batch size
  batch_size: 8

  # Inference optimization
  inference_batch_size: 32
  max_batch_tokens: 8192

  # Server settings
  host: "0.0.0.0"
  port: 8000
  reload: true

  # API metadata
  title: "AI Text Detector API"
  version: "1.0.0"
  description: "Word-level AI-generated text detection API"
