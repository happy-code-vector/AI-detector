fastapi>=0.100.0
uvicorn[standard]>=0.22.0
pydantic>=2.0
pydantic-settings>=2.0
torch>=2.0.0
transformers>=4.30.0
python-multipart
pytest
httpx
pyyaml
peft>=0.6.0

# ONNX Runtime for optimized CPU inference (2-4x faster than PyTorch)
onnxruntime>=1.16.0
onnx>=1.14.0
numpy>=1.24.0
